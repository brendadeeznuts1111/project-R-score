//! Microstructural Simulator for Pattern Validation
//!
//! Tick-accurate simulator that accounts for latency, slippage, and account limits.
//! Integrates with Kalman Filter Suite for pattern detection and execution simulation.

use crate::kalman_filter_suite::*;
use crate::types::{TimestampNs, PriceCents, MarketType, Platform};
use crate::tick_sim_backtester::{TradeRecord, Position};
use std::collections::{HashMap, VecDeque};
use serde::{Serialize, Deserialize};
use tracing::{info, warn, debug, error};
use rand::{thread_rng, Rng};

/// Synchronized tick bundle for multi-market patterns
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SyncedTickBundle {
    /// Timestamp in nanoseconds
    pub timestamp_ns: TimestampNs,
    /// HT market data (if available)
    pub ht: Option<TickData>,
    /// FT market data (if available)
    pub ft: Option<TickData>,
    /// Multiple market data for propagation patterns
    pub multiple_markets: Option<HashMap<String, TickData>>,
    /// Time remaining in game (for in-play patterns)
    pub time_remaining: Option<f64>,
    /// Game context
    pub game_context: Option<GameContext>,
}

/// Individual tick data
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TickData {
    /// Market identifier
    pub market_id: String,
    /// Platform/bookmaker
    pub platform: Platform,
    /// Price/line value
    pub price: f64,
    /// Size/liquidity
    pub size: f64,
    /// Price delta from previous tick
    pub price_delta: f64,
    /// Book identifier
    pub book: String,
}

/// Game context information
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GameContext {
    /// Sport type
    pub sport: String,
    /// Teams playing
    pub teams: (String, String),
    /// Current period
    pub period: u8,
    /// Time remaining in seconds
    pub time_remaining: f64,
    /// Score
    pub score: (u16, u16),
}

/// Trade trigger generated by pattern detection
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Trigger {
    /// Pattern ID
    pub pattern: u16,
    /// Target book
    pub book: String,
    /// Target price
    pub target_price: f64,
    /// Theoretical maximum edge
    pub theoretical_max: f64,
    /// Window duration in seconds
    pub window_duration: f64,
    /// Position size
    pub size: f64,
    /// Confidence level
    pub confidence: f64,
    /// Expected edge
    pub expected_edge: f64,
    /// Trigger timestamp
    pub timestamp_ns: TimestampNs,
}

/// Latency model for realistic simulation
#[derive(Debug, Clone)]
pub struct LatencyModel {
    /// Base latency per book (microseconds)
    pub base_latency: HashMap<String, f64>,
    /// Jitter standard deviation (microseconds)
    pub jitter_std: f64,
    /// Queue delay model
    pub queue_delay: QueueDelayModel,
}

/// Queue delay model for execution simulation
#[derive(Debug, Clone)]
pub struct QueueDelayModel {
    /// Average queue depth
    pub avg_depth: f64,
    /// Queue processing rate (trades/second)
    pub processing_rate: f64,
    /// Queue overflow probability
    pub overflow_prob: f64,
}

/// Account health tracking
#[derive(Debug, Clone)]
pub struct AccountHealth {
    /// Book identifier
    pub book: String,
    /// Health score (0-1)
    pub health_score: f64,
    /// Recent trade P&L
    pub recent_pnl: VecDeque<f64>,
    /// Trade frequency (trades/hour)
    pub trade_frequency: f64,
    /// Sharp score
    pub sharp_score: f64,
    /// Limit status
    pub limit_status: LimitStatus,
}

/// Account limiting status
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum LimitStatus {
    /// No limits
    None,
    /// Soft limits (reduced size)
    Soft,
    /// Hard limits (no trading)
    Hard,
}

/// Simulation results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SimulationResults {
    /// Total P&L
    pub total_pnl: f64,
    /// Sharpe ratio
    pub sharpe_ratio: f64,
    /// Maximum drawdown
    pub max_drawdown: f64,
    /// Total trades executed
    pub total_trades: u32,
    /// Winning trades
    pub winning_trades: u32,
    /// Account lifespan (trades)
    pub account_lifespan_trades: u32,
    /// Edge capture rate
    pub edge_capture_rate: f64,
    /// Average execution latency (microseconds)
    pub avg_execution_latency_us: f64,
    /// Pattern-specific results
    pub pattern_results: HashMap<u16, PatternResult>,
    /// Equity curve
    pub equity_curve: Vec<EquityPoint>,
}

/// Pattern-specific results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PatternResult {
    /// Pattern ID
    pub pattern_id: u16,
    /// Total trades
    pub total_trades: u32,
    /// Win rate
    pub win_rate: f64,
    /// Average edge captured
    pub avg_edge_captured: f64,
    /// Average execution latency
    pub avg_execution_latency_us: f64,
    /// Account impact
    pub account_impact: f64,
}

/// Equity curve point
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EquityPoint {
    /// Timestamp
    pub timestamp_ns: TimestampNs,
    /// Equity value
    pub equity: f64,
    /// Open positions
    pub open_positions: u32,
    /// Account health
    pub account_health: f64,
}

/// Microstructural simulator
pub struct MicrostructuralSimulator {
    /// Pattern-specific Kalman filters
    pub filters: HashMap<u16, Box<dyn KalmanFilterTrait>>,
    /// Simulation configuration
    pub config: SimulationConfig,
    /// Latency model
    pub latency_model: LatencyModel,
    /// Account health tracking
    pub account_health: HashMap<String, AccountHealth>,
    /// Trade log
    pub trade_log: Vec<TradeRecord>,
    /// Current positions
    pub positions: HashMap<String, Position>,
    /// Equity curve
    pub equity_curve: Vec<EquityPoint>,
    /// Current capital
    pub current_capital: f64,
    /// Starting capital
    pub start_capital: f64,
    /// Pattern statistics
    pub pattern_stats: HashMap<u16, PatternStats>,
}

/// Simulation configuration
#[derive(Debug, Clone)]
pub struct SimulationConfig {
    /// Initial capital
    pub initial_capital: f64,
    /// Maximum position size
    pub max_position_size: f64,
    /// Transaction cost rate
    pub transaction_cost_rate: f64,
    /// Minimum edge threshold
    pub min_edge_threshold: f64,
    /// Kelly fraction multiplier
    pub kelly_multiplier: f64,
    /// Account health thresholds
    pub health_thresholds: HealthThresholds,
    /// Simulation time range
    pub time_range: TimeRange,
}

/// Health thresholds for account limiting
#[derive(Debug, Clone)]
pub struct HealthThresholds {
    /// Soft limit threshold
    pub soft_limit: f64,
    /// Hard limit threshold
    pub hard_limit: f64,
    /// Health decay rate
    pub decay_rate: f64,
}

/// Time range for simulation
#[derive(Debug, Clone)]
pub struct TimeRange {
    /// Start timestamp
    pub start_ns: TimestampNs,
    /// End timestamp
    pub end_ns: TimestampNs,
}

/// Pattern statistics tracking
#[derive(Debug, Clone, Default)]
pub struct PatternStats {
    /// Total opportunities detected
    pub total_opportunities: u32,
    /// Total trades executed
    pub total_trades: u32,
    /// Winning trades
    pub winning_trades: u32,
    /// Total edge captured
    pub total_edge_captured: f64,
    /// Total theoretical edge
    pub total_theoretical_edge: f64,
    /// Average execution latency
    pub avg_execution_latency_us: f64,
}

impl Default for SimulationConfig {
    fn default() -> Self {
        Self {
            initial_capital: 10000.0,
            max_position_size: 1000.0,
            transaction_cost_rate: 0.001, // 0.1%
            min_edge_threshold: 0.5,
            kelly_multiplier: 0.5, // Half-Kelly
            health_thresholds: HealthThresholds {
                soft_limit: 0.3,
                hard_limit: 0.1,
                decay_rate: 0.95,
            },
            time_range: TimeRange {
                start_ns: 0,
                end_ns: u64::MAX,
            },
        }
    }
}

impl LatencyModel {
    /// Create new latency model
    pub fn new() -> Self {
        let mut base_latency = HashMap::new();
        base_latency.insert("pinnacle".to_string(), 50.0); // 50μs
        base_latency.insert("draftkings".to_string(), 75.0); // 75μs
        base_latency.insert("betfair".to_string(), 100.0); // 100μs
        base_latency.insert("fan_duel".to_string(), 80.0); // 80μs

        Self {
            base_latency,
            jitter_std: 10.0, // 10μs jitter
            queue_delay: QueueDelayModel {
                avg_depth: 2.0,
                processing_rate: 1000.0, // 1000 trades/sec
                overflow_prob: 0.01,
            },
        }
    }

    /// Apply latency to tick
    pub fn apply(&self, mut tick: SyncedTickBundle) -> SyncedTickBundle {
        let mut rng = thread_rng();

        // Add jitter to timestamp
        let jitter = rng.gen_range(-self.jitter_std..=self.jitter_std);
        tick.timestamp_ns = tick.timestamp_ns + (jitter * 1000.0) as u64; // Convert μs to ns

        tick
    }

    /// Get latency for specific book
    pub fn get_latency(&self, book: &str) -> f64 {
        let base = self.base_latency.get(book).unwrap_or(&100.0);
        let mut rng = thread_rng();
        let jitter = rng.gen_range(-self.jitter_std..=self.jitter_std);
        base + jitter
    }
}

impl AccountHealth {
    /// Create new account health tracker
    pub fn new(book: String) -> Self {
        Self {
            book,
            health_score: 1.0,
            recent_pnl: VecDeque::new(),
            trade_frequency: 0.0,
            sharp_score: 0.0,
            limit_status: LimitStatus::None,
        }
    }

    /// Update with new trade result
    pub fn update_trade(&mut self, pnl: f64, config: &SimulationConfig) {
        // Add to recent P&L
        self.recent_pnl.push_back(pnl);
        if self.recent_pnl.len() > 100 {
            self.recent_pnl.pop_front();
        }

        // Update health score based on recent performance
        let avg_pnl = self.recent_pnl.iter().sum::<f64>() / self.recent_pnl.len() as f64;
        self.health_score = (self.health_score * config.health_thresholds.decay_rate +
                           avg_pnl.abs() * (1.0 - config.health_thresholds.decay_rate)).min(1.0).max(0.0);

        // Update sharp score
        self.update_sharp_score();

        // Update limit status
        self.limit_status = if self.health_score < config.health_thresholds.hard_limit {
            LimitStatus::Hard
        } else if self.health_score < config.health_thresholds.soft_limit {
            LimitStatus::Soft
        } else {
            LimitStatus::None
        };
    }

    /// Update sharp score calculation
    fn update_sharp_score(&mut self) {
        if self.recent_pnl.len() < 10 {
            return;
        }

        let pnl_values: Vec<f64> = self.recent_pnl.iter().copied().collect();
        let mean = pnl_values.iter().sum::<f64>() / pnl_values.len() as f64;
        let variance = pnl_values.iter()
            .map(|x| (x - mean).powi(2))
            .sum::<f64>() / (pnl_values.len() - 1) as f64;
        let std_dev = variance.sqrt();

        if std_dev > 0.0 {
            self.sharp_score = (mean / std_dev).max(0.0);
        }
    }

    /// Check if trading is allowed
    pub fn can_trade(&self) -> bool {
        matches!(self.limit_status, LimitStatus::None)
    }

    /// Get allowed position size multiplier
    pub fn get_size_multiplier(&self) -> f64 {
        match self.limit_status {
            LimitStatus::None => 1.0,
            LimitStatus::Soft => 0.5,
            LimitStatus::Hard => 0.0,
        }
    }
}

impl MicrostructuralSimulator {
    /// Create new microstructural simulator
    pub fn new(config: SimulationConfig) -> Self {
        Self {
            filters: HashMap::new(),
            config,
            latency_model: LatencyModel::new(),
            account_health: HashMap::new(),
            trade_log: Vec::new(),
            positions: HashMap::new(),
            equity_curve: Vec::new(),
            current_capital: config.initial_capital,
            start_capital: config.initial_capital,
            pattern_stats: HashMap::new(),
        }
    }

    /// Add pattern filter
    pub fn add_pattern_filter(&mut self, pattern_id: u16, filter: Box<dyn KalmanFilterTrait>) {
        self.filters.insert(pattern_id, filter);
    }

    /// Initialize account health trackers
    pub fn initialize_accounts(&mut self, books: Vec<String>) {
        for book in books {
            self.account_health.insert(book.clone(), AccountHealth::new(book));
        }
    }

    /// Run historical simulation
    pub async fn run_historical(&mut self, tick_stream: Vec<SyncedTickBundle>) -> Result<SimulationResults, Box<dyn std::error::Error + Send + Sync>> {
        info!("Starting historical simulation with {} ticks", tick_stream.len());

        let mut last_equity_update = 0;

        for tick in tick_stream {
            // Apply latency jitter
            let effective_tick = self.latency_model.apply(tick);

            // Skip if outside time range
            if effective_tick.timestamp_ns < self.config.time_range.start_ns ||
               effective_tick.timestamp_ns > self.config.time_range.end_ns {
                continue;
            }

            // Update all filters and detect triggers
            let triggers = self.evaluate_pattern_triggers(&effective_tick).await?;

            // Execute trades for valid triggers
            for trigger in triggers {
                if self.execute_trade(trigger).await? {
                    // Update equity curve every 100 trades
                    if self.trade_log.len() > last_equity_update + 100 {
                        self.record_equity_point(effective_tick.timestamp_ns);
                        last_equity_update = self.trade_log.len();
                    }
                }
            }
        }

        // Record final equity point
        self.record_equity_point(std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_nanos() as u64);

        // Generate results
        self.generate_results()
    }

    /// Evaluate pattern triggers across all filters
    async fn evaluate_pattern_triggers(&mut self, tick: &SyncedTickBundle) -> Result<Vec<Trigger>, Box<dyn std::error::Error + Send + Sync>> {
        let mut triggers = Vec::new();

        // Pattern 51: HT → FT lag
        if let (Some(filter), Some(ht_data), Some(ft_data)) = (
            self.filters.get_mut(&51),
            &tick.ht,
            &tick.ft
        ) {
            // Update filter with both markets
            let mut ht_filter = filter.as_any().downcast_ref::<HalfTimeInferenceKF>()
                .ok_or("Failed to downcast HT inference filter")?;

            ht_filter.update_with_both_markets(ht_data.price_delta, ft_data.price)?;
            ht_filter.predict();

            // Check for trigger
            let predicted_ft = ht_filter.predict_ft_total();
            let edge = (predicted_ft - ft_data.price).abs();

            if edge > self.config.min_edge_threshold && ht_filter.get_regime() == Regime::Steam {
                let stats = self.pattern_stats.entry(51).or_default();
                stats.total_opportunities += 1;

                let confidence = self.calculate_confidence(edge, ht_filter.get_uncertainty());
                let size = self.kelly_sizing(edge, confidence, &ft_data.book);

                triggers.push(Trigger {
                    pattern: 51,
                    book: ft_data.book.clone(),
                    target_price: predicted_ft,
                    theoretical_max: edge * 100.0,
                    window_duration: 30.0,
                    size,
                    confidence,
                    expected_edge: edge,
                    timestamp_ns: tick.timestamp_ns,
                });
            }
        }

        // Pattern 68: Steam propagation path
        if let (Some(filter), Some(markets)) = (self.filters.get_mut(&68), &tick.multiple_markets) {
            let mut prop_filter = filter.as_any().downcast_ref::<PropagationPathKF>()
                .ok_or("Failed to downcast propagation filter")?;

            prop_filter.update_partial_observation(markets)?;
            prop_filter.predict();

            if prop_filter.get_regime() == Regime::Steam {
                // Check propagation delay to props
                if let Some(props_data) = markets.get("props") {
                    let delay = prop_filter.get_propagation_delay("ml", "props");

                    if delay < 3.0 { // 3s window
                        let positions = prop_filter.get_market_positions();
                        if let Some(&predicted_props) = positions.get("props") {
                            let edge = (predicted_props - props_data.price).abs();

                            if edge > self.config.min_edge_threshold {
                                let stats = self.pattern_stats.entry(68).or_default();
                                stats.total_opportunities += 1;

                                let confidence = self.calculate_confidence(edge, prop_filter.get_uncertainty());
                                let size = self.kelly_sizing(edge, confidence, &props_data.book);

                                triggers.push(Trigger {
                                    pattern: 68,
                                    book: props_data.book.clone(),
                                    target_price: predicted_props,
                                    theoretical_max: edge * 100.0,
                                    window_duration: delay,
                                    size,
                                    confidence,
                                    expected_edge: edge,
                                    timestamp_ns: tick.timestamp_ns,
                                });
                            }
                        }
                    }
                }
            }
        }

        // Pattern 75: In-play velocity convexity
        if let (Some(filter), Some(time_remaining)) = (self.filters.get_mut(&75), tick.time_remaining) {
            let mut vel_filter = filter.as_any().downcast_ref::<VelocityConvexityKF>()
                .ok_or("Failed to downcast velocity convexity filter")?;

            vel_filter.predict_with_time(time_remaining);

            // Update with current price (from any market)
            if let Some(market_data) = tick.multiple_markets.as_ref()
                .and_then(|m| m.values().next()) {

                let obs = vec![market_data.price];
                vel_filter.update(&obs)?;

                if let Some(predicted_price) = vel_filter.detect_late_game_opportunity(market_data.price) {
                    let edge = (predicted_price - market_data.price).abs();

                    if edge > self.config.min_edge_threshold && time_remaining < 300.0 { // 5 minutes
                        let stats = self.pattern_stats.entry(75).or_default();
                        stats.total_opportunities += 1;

                        let confidence = self.calculate_confidence(edge, vel_filter.get_uncertainty());
                        let size = self.kelly_sizing(edge, confidence, &market_data.book);

                        triggers.push(Trigger {
                            pattern: 75,
                            book: market_data.book.clone(),
                            target_price: predicted_price,
                            theoretical_max: edge * 100.0,
                            window_duration: 5.0,
                            size,
                            confidence,
                            expected_edge: edge,
                            timestamp_ns: tick.timestamp_ns,
                        });
                    }
                }
            }
        }

        Ok(triggers)
    }

    /// Execute trade based on trigger
    async fn execute_trade(&mut self, trigger: Trigger) -> Result<bool, Box<dyn std::error::Error + Send + Sync>> {
        // Check account health
        let account_health = self.account_health.get_mut(&trigger.book)
            .ok_or(format!("No account health for book: {}", trigger.book))?;

        if !account_health.can_trade() {
            return Ok(false);
        }

        // Apply size multiplier based on account limits
        let adjusted_size = trigger.size * account_health.get_size_multiplier();

        if adjusted_size <= 0.0 {
            return Ok(false);
        }

        // Simulate execution with slippage
        let execution_price = self.simulate_slippage(&trigger.book, trigger.target_price).await?;
        let execution_latency = self.latency_model.get_latency(&trigger.book);

        // Calculate P&L
        let edge_captured = (execution_price - trigger.target_price).abs();
        let theoretical_edge = trigger.expected_edge;
        let edge_capture_rate = if theoretical_edge > 0.0 {
            edge_captured / theoretical_edge
        } else {
            0.0
        };

        let pnl = edge_captured * adjusted_size - (self.config.transaction_cost_rate * adjusted_size);

        // Update capital
        self.current_capital += pnl;

        // Create position (simplified)
        let position = Position {
            market_id: format!("pattern_{}_{}", trigger.pattern, trigger.book),
            direction: if execution_price > trigger.target_price { 1 } else { -1 },
            size: adjusted_size,
            entry_price: execution_price,
            entry_timestamp_ns: trigger.timestamp_ns,
            pattern_id: trigger.pattern,
            expected_alpha: trigger.expected_edge,
        };

        self.positions.insert(position.market_id.clone(), position);

        // Record trade
        let trade_record = TradeRecord {
            timestamp_ns: trigger.timestamp_ns,
            pnl,
            size: adjusted_size,
            execution_latency_us: execution_latency,
            confidence: trigger.confidence,
        };

        self.trade_log.push(trade_record.clone());

        // Update account health
        account_health.update_trade(pnl, &self.config);

        // Update pattern statistics
        let stats = self.pattern_stats.entry(trigger.pattern).or_default();
        stats.total_trades += 1;
        if pnl > 0.0 {
            stats.winning_trades += 1;
        }
        stats.total_edge_captured += edge_captured;
        stats.total_theoretical_edge += theoretical_edge;
        stats.avg_execution_latency_us = (stats.avg_execution_latency_us * (stats.total_trades - 1) as f64 + execution_latency) / stats.total_trades as f64;

        info!("Executed trade: Pattern {} on {}, P&L: ${:.2}, Edge captured: {:.1}%",
              trigger.pattern, trigger.book, pnl, edge_capture_rate * 100.0);

        Ok(true)
    }

    /// Simulate execution slippage
    async fn simulate_slippage(&self, book: &str, target_price: f64) -> Result<f64, Box<dyn std::error::Error + Send + Sync>> {
        let mut rng = thread_rng();

        // Slippage based on book and latency
        let base_slippage = match book {
            "pinnacle" => 0.001, // 0.1%
            "draftkings" => 0.002, // 0.2%
            "betfair" => 0.0015, // 0.15%
            _ => 0.002, // 0.2% default
        };

        let slippage = base_slippage * (1.0 + rng.gen_range(-0.5..=0.5));
        let slippage_amount = target_price * slippage;

        // Random direction of slippage
        if rng.gen_bool(0.5) {
            Ok(target_price + slippage_amount)
        } else {
            Ok(target_price - slippage_amount)
        }
    }

    /// Calculate confidence based on edge and uncertainty
    fn calculate_confidence(&self, edge: f64, uncertainty: f64) -> f64 {
        if uncertainty <= 0.0 {
            return 0.5;
        }

        let signal_to_noise = edge / uncertainty;
        (signal_to_noise / (1.0 + signal_to_noise)).min(0.95).max(0.05)
    }

    /// Kelly criterion position sizing
    fn kelly_sizing(&self, edge: f64, confidence: f64, book: &str) -> f64 {
        if edge <= 0.0 {
            return 0.0;
        }

        // Simplified Kelly calculation
        let win_rate = confidence;
        let avg_win = edge * 100.0; // Convert to dollars
        let avg_loss = edge * 50.0; // Assume losses are smaller

        let kelly_fraction = (win_rate * avg_win - (1.0 - win_rate) * avg_loss) / avg_win;
        let conservative_kelly = kelly_fraction * self.config.kelly_multiplier;

        // Apply position limits
        let max_size = self.config.max_position_size;
        let capital_fraction = self.current_capital * 0.1; // Max 10% of capital

        (conservative_kelly * capital_fraction).min(max_size).max(0.01)
    }

    /// Record equity curve point
    fn record_equity_point(&mut self, timestamp_ns: TimestampNs) {
        let avg_health = self.account_health.values()
            .map(|h| h.health_score)
            .sum::<f64>() / self.account_health.len().max(1) as f64;

        let equity_point = EquityPoint {
            timestamp_ns,
            equity: self.current_capital,
            open_positions: self.positions.len() as u32,
            account_health: avg_health,
        };

        self.equity_curve.push(equity_point);
    }

    /// Generate simulation results
    fn generate_results(&self) -> Result<SimulationResults, Box<dyn std::error::Error + Send + Sync>> {
        let total_pnl = self.current_capital - self.start_capital;
        let roi_percent = (total_pnl / self.start_capital) * 100.0;

        let total_trades = self.trade_log.len() as u32;
        let winning_trades = self.trade_log.iter().filter(|t| t.pnl > 0.0).count() as u32;

        // Calculate Sharpe ratio
        let returns: Vec<f64> = self.trade_log.iter().map(|t| t.pnl).collect();
        let sharpe_ratio = if returns.len() > 1 {
            let mean = returns.iter().sum::<f64>() / returns.len() as f64;
            let variance = returns.iter()
                .map(|r| (r - mean).powi(2))
                .sum::<f64>() / (returns.len() - 1) as f64;
            let std_dev = variance.sqrt();
            if std_dev > 0.0 {
                (mean / std_dev) * (252.0_f64).sqrt() // Annualized
            } else {
                0.0
            }
        } else {
            0.0
        };

        // Calculate maximum drawdown
        let max_drawdown = self.calculate_max_drawdown();

        // Calculate edge capture rate
        let total_edge_captured: f64 = self.pattern_stats.values()
            .map(|s| s.total_edge_captured)
            .sum();
        let total_theoretical_edge: f64 = self.pattern_stats.values()
            .map(|s| s.total_theoretical_edge)
            .sum();
        let edge_capture_rate = if total_theoretical_edge > 0.0 {
            total_edge_captured / total_theoretical_edge
        } else {
            0.0
        };

        // Average execution latency
        let avg_execution_latency_us = if total_trades > 0 {
            self.trade_log.iter().map(|t| t.execution_latency_us).sum::<f64>() / total_trades as f64
        } else {
            0.0
        };

        // Account lifespan (trades until first hard limit)
        let account_lifespan_trades = self.trade_log.iter()
            .position(|_| {
                self.account_health.values().any(|h| matches!(h.limit_status, LimitStatus::Hard))
            })
            .unwrap_or(self.trade_log.len()) as u32;

        // Pattern-specific results
        let mut pattern_results = HashMap::new();
        for (pattern_id, stats) in &self.pattern_stats {
            let win_rate = if stats.total_trades > 0 {
                stats.winning_trades as f64 / stats.total_trades as f64
            } else {
                0.0
            };

            let avg_edge_captured = if stats.total_trades > 0 {
                stats.total_edge_captured / stats.total_trades as f64
            } else {
                0.0
            };

            pattern_results.insert(*pattern_id, PatternResult {
                pattern_id: *pattern_id,
                total_trades: stats.total_trades,
                win_rate,
                avg_edge_captured,
                avg_execution_latency_us: stats.avg_execution_latency_us,
                account_impact: 0.0, // TODO: Calculate account impact
            });
        }

        Ok(SimulationResults {
            total_pnl,
            sharpe_ratio,
            max_drawdown,
            total_trades,
            winning_trades,
            account_lifespan_trades,
            edge_capture_rate,
            avg_execution_latency_us,
            pattern_results,
            equity_curve: self.equity_curve.clone(),
        })
    }

    /// Calculate maximum drawdown from equity curve
    fn calculate_max_drawdown(&self) -> f64 {
        if self.equity_curve.is_empty() {
            return 0.0;
        }

        let mut max_drawdown = 0.0;
        let mut peak_equity = self.start_capital;

        for point in &self.equity_curve {
            if point.equity > peak_equity {
                peak_equity = point.equity;
            }

            let drawdown = (peak_equity - point.equity) / peak_equity;
            if drawdown > max_drawdown {
                max_drawdown = drawdown;
            }
        }

        max_drawdown
    }
}

// Helper trait for downcasting
trait AsAny {
    fn as_any(&self) -> &dyn std::any::Any;
}

impl<T: std::any::Any> AsAny for T {
    fn as_any(&self) -> &dyn std::any::Any {
        self
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_latency_model() {
        let model = LatencyModel::new();

        let latency = model.get_latency("pinnacle");
        assert!(latency > 40.0 && latency < 60.0); // Should be around 50μs ± jitter
    }

    #[test]
    fn test_account_health() {
        let mut health = AccountHealth::new("test_book".to_string());
        let config = SimulationConfig::default();

        // Initial health should be good
        assert!(health.can_trade());
        assert_eq!(health.get_size_multiplier(), 1.0);

        // Update with bad trades
        for _ in 0..10 {
            health.update_trade(-10.0, &config);
        }

        // Health should deteriorate
        assert!(!health.can_trade());
    }

    #[test]
    fn test_microstructural_simulator_creation() {
        let config = SimulationConfig::default();
        let simulator = MicrostructuralSimulator::new(config);

        assert_eq!(simulator.current_capital, 10000.0);
        assert_eq!(simulator.start_capital, 10000.0);
    }

    #[tokio::test]
    async fn test_kelly_sizing() {
        let config = SimulationConfig::default();
        let simulator = MicrostructuralSimulator::new(config);

        let size = simulator.kelly_sizing(1.0, 0.6, "pinnacle");
        assert!(size > 0.0);
        assert!(size <= simulator.config.max_position_size);
    }

    #[test]
    fn test_confidence_calculation() {
        let config = SimulationConfig::default();
        let simulator = MicrostructuralSimulator::new(config);

        let confidence = simulator.calculate_confidence(1.0, 0.5);
        assert!(confidence > 0.0);
        assert!(confidence <= 1.0);
    }
}
