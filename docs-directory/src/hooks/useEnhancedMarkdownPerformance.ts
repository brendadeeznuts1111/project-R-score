import { useState, useEffect, useRef } from 'react';\n\ninterface EnhancedProfile {\n  documentSize: number;\n  parseTime: number;\n  renderTime: number;\n  memory: number;\n  throughput: number;\n  complexity: 'simple' | 'moderate' | 'complex' | 'extreme';\n  features: { headings: number; links: number; tables: number; tasks: number; math: number };\n  recommendations: string[];\n}\n\ninterface BenchmarkOptions {\n  iterations?: number;\n  warmup?: boolean;\n  memoryTracking?: boolean;\n  gcBetweenRuns?: boolean;\n}\n\ninterface PerformanceReport {\n  profiles: EnhancedProfile[];\n  summary: {\n    totalTests: number;\n    averageThroughput: number;\n    fastestParse: number;\n    slowestParse: number;\n    memoryEfficiency: number;\n    performanceScore: number;\n  };\n  timestamp: string;\n}\n\nexport function useEnhancedMarkdownPerformance() {\n  const [isBenchmarking, setIsBenchmarking] = useState(false);\n  const [currentProfile, setCurrentProfile] = useState<EnhancedProfile | null>(null);\n  const [benchmarkHistory, setBenchmarkHistory] = useState<EnhancedProfile[]>([]);\n  const [performanceReport, setPerformanceReport] = useState<PerformanceReport | null>(null);\n  \n  const performanceRef = useRef<Performance | null>(null);\n  const memoryBaseline = useRef<number>(0);\n  \n  useEffect(() => {\n    performanceRef.current = typeof performance !== 'undefined' ? performance : null;\n    // Establish memory baseline\n    memoryBaseline.current = getMemoryUsage();\n  }, []);\n\n  // Enhanced benchmark function based on your example\n  const benchmark = async (md: string, options: BenchmarkOptions = {}): Promise<EnhancedProfile> => {\n    const {\n      iterations = 1000,\n      warmup = true,\n      memoryTracking = true,\n      gcBetweenRuns = false\n    } = options;\n    \n    setIsBenchmarking(true);\n    \n    try {\n      // Warmup runs to stabilize performance\n      if (warmup) {\n        for (let i = 0; i < Math.min(50, iterations / 10); i++) {\n          await parseMarkdown(md);\n        }\n      }\n      \n      const start = performanceRef.current?.now() || Date.now();\n      let totalTime = 0;\n      let memPeak = 0;\n      let minTime = Infinity;\n      let maxTime = 0;\n      \n      for (let i = 0; i < iterations; i++) {\n        // Garbage collection between runs if requested\n        if (gcBetweenRuns && i > 0 && i % 100 === 0) {\n          if (typeof Bun !== 'undefined' && Bun.gc) {\n            Bun.gc();\n          } else if (typeof global !== 'undefined' && (global as any).gc) {\n            (global as any).gc();\n          }\n        }\n        \n        const t0 = performanceRef.current?.now() || Date.now();\n        await parseMarkdown(md);\n        const t1 = performanceRef.current?.now() || Date.now();\n        \n        const iterationTime = t1 - t0;\n        totalTime += iterationTime;\n        minTime = Math.min(minTime, iterationTime);\n        maxTime = Math.max(maxTime, iterationTime);\n        \n        // Track memory usage\n        if (memoryTracking) {\n          const currentMemory = getMemoryUsage();\n          memPeak = Math.max(memPeak, currentMemory);\n        }\n        \n        // Yield control periodically\n        if (i % 100 === 0) {\n          await new Promise(resolve => setTimeout(resolve, 0));\n        }\n      }\n      \n      const avgTime = totalTime / iterations;\n      const features = analyzeMarkdownFeatures(md);\n      \n      const profile: EnhancedProfile = {\n        documentSize: md.length,\n        parseTime: avgTime,\n        renderTime: 0, // HTML output included in parse time\n        memory: memPeak - memoryBaseline.current,\n        throughput: md.length / (avgTime / 1000),\n        complexity: determineComplexity(md.length, features),\n        features,\n        recommendations: generateRecommendations(avgTime, md.length, memPeak, features)\n      };\n      \n      setCurrentProfile(profile);\n      setBenchmarkHistory(prev => [...prev.slice(-19), profile]); // Keep last 20\n      \n      return profile;\n    } finally {\n      setIsBenchmarking(false);\n    }\n  };\n\n  // Multiple document benchmark\n  const benchmarkSuite = async (documents: Record<string, string>, options: BenchmarkOptions = {}): Promise<PerformanceReport> => {\n    const profiles: EnhancedProfile[] = [];\n    \n    for (const [name, markdown] of Object.entries(documents)) {\n      console.log(`Benchmarking ${name}...`);\n      const profile = await benchmark(markdown, options);\n      profiles.push(profile);\n      \n      // Small delay between tests\n      await new Promise(resolve => setTimeout(resolve, 100));\n    }\n    \n    const summary = calculateSummary(profiles);\n    const report: PerformanceReport = {\n      profiles,\n      summary,\n      timestamp: new Date().toISOString()\n    };\n    \n    setPerformanceReport(report);\n    return report;\n  };\n\n  // Parse markdown using Bun or fallback\n  const parseMarkdown = async (md: string): Promise<void> => {\n    if (typeof Bun !== 'undefined' && Bun.markdown) {\n      // Use Bun's markdown parser\n      Bun.markdown.html(md);\n    } else {\n      // Fallback simulation for non-Bun environments\n      const div = document.createElement('div');\n      div.innerHTML = md\n        .replace(/^### (.*$)/gim, '<h3>$1</h3>')\n        .replace(/^## (.*$)/gim, '<h2>$1</h2>')\n        .replace(/^# (.*$)/gim, '<h1>$1</h1>')\n        .replace(/\\*\\*(.*)\\*\\*/gim, '<strong>$1</strong>')\n        .replace(/\\*(.*)\\*/gim, '<em>$1</em>')\n        .replace(/\\`([^`]*)\\`/gim, '<code>$1</code>')\n        .replace(/\\[([^\\]]+)\\]\\(([^)]+)\\)/g, '<a href=\"$2\">$1</a>')\n        .replace(/\\|(.*)\\|/g, '<table><tr><td>$1</td></tr></table>');\n    }\n  };\n\n  // Analyze markdown features (simulating BunMarkdown.analyze)\n  const analyzeMarkdownFeatures = (md: string) => {\n    const features = {\n      headings: (md.match(/^#{1,6}\\s+/gm) || []).length,\n      links: (md.match(/\\[([^\\]]+)\\]\\(([^)]+)\\)/g) || []).length,\n      tables: Math.floor((md.match(/\\|.*\\|/g) || []).length / 2),\n      tasks: (md.match(/- \\[[ x]\\]/g) || []).length,\n      math: (md.match(/\\$\\$[^$]*\\$\\$/g) || []).length\n    };\n    \n    return features;\n  };\n\n  // Determine document complexity\n  const determineComplexity = (size: number, features: ReturnType<typeof analyzeMarkdownFeatures>): 'simple' | 'moderate' | 'complex' | 'extreme' => {\n    const featureCount = Object.values(features).reduce((a, b) => a + b, 0);\n    \n    if (size > 50_000 || featureCount > 100) return 'extreme';\n    if (size > 10_000 || featureCount > 50) return 'complex';\n    if (size > 1_000 || featureCount > 10) return 'moderate';\n    return 'simple';\n  };\n\n  // Generate performance recommendations\n  const generateRecommendations = (\n    avgTime: number, \n    docSize: number, \n    memory: number, \n    features: ReturnType<typeof analyzeMarkdownFeatures>\n  ): string[] => {\n    const recommendations: string[] = [];\n    \n    // Performance recommendations\n    if (avgTime > 10) {\n      recommendations.push('Consider Bun edge runtime for sub-1ms performance');\n    }\n    \n    if (avgTime > 5) {\n      recommendations.push('Document complexity is high - consider splitting into smaller sections');\n    }\n    \n    // Memory recommendations\n    if (memory > 100) {\n      recommendations.push('High memory usage detected - enable garbage collection optimization');\n    }\n    \n    // Size recommendations\n    if (docSize > 100_000) {\n      recommendations.push('Large document detected - consider streaming parser for better memory efficiency');\n    }\n    \n    // Throughput recommendations\n    const throughput = docSize / (avgTime / 1000);\n    if (throughput < 10_000) {\n      recommendations.push('Low throughput detected - optimize markdown structure for better parsing');\n    }\n    \n    // Feature-specific recommendations\n    if (features.tables > 10) {\n      recommendations.push('Many tables detected - consider table optimization for better performance');\n    }\n    \n    if (features.math > 5) {\n      recommendations.push('Multiple math expressions - consider LaTeX optimization');\n    }\n    \n    if (features.tasks > 20) {\n      recommendations.push('Many task lists - consider task parsing optimization');\n    }\n    \n    if (recommendations.length === 0) {\n      recommendations.push('Excellent performance! No optimizations needed.');\n    }\n    \n    return recommendations;\n  };\n\n  // Calculate performance summary\n  const calculateSummary = (profiles: EnhancedProfile[]) => {\n    if (profiles.length === 0) {\n      return {\n        totalTests: 0,\n        averageThroughput: 0,\n        fastestParse: 0,\n        slowestParse: 0,\n        memoryEfficiency: 0,\n        performanceScore: 0\n      };\n    }\n    \n    const throughputs = profiles.map(p => p.throughput);\n    const parseTimes = profiles.map(p => p.parseTime);\n    const memoryUsages = profiles.map(p => p.memory);\n    \n    const averageThroughput = throughputs.reduce((a, b) => a + b, 0) / throughputs.length;\n    const fastestParse = Math.min(...parseTimes);\n    const slowestParse = Math.max(...parseTimes);\n    const memoryEfficiency = memoryUsages.reduce((a, b) => a + b, 0) / memoryUsages.length;\n    \n    // Calculate performance score (0-100)\n    let performanceScore = 0;\n    \n    // Speed component (40%)\n    if (fastestParse < 1) performanceScore += 40;\n    else if (fastestParse < 5) performanceScore += 30;\n    else if (fastestParse < 10) performanceScore += 20;\n    else performanceScore += 10;\n    \n    // Throughput component (30%)\n    if (averageThroughput > 50_000) performanceScore += 30;\n    else if (averageThroughput > 20_000) performanceScore += 20;\n    else if (averageThroughput > 10_000) performanceScore += 10;\n    \n    // Memory efficiency component (20%)\n    if (memoryEfficiency < 10) performanceScore += 20;\n    else if (memoryEfficiency < 50) performanceScore += 15;\n    else if (memoryEfficiency < 100) performanceScore += 10;\n    \n    // Consistency component (10%)\n    const consistency = 1 - (slowestParse - fastestParse) / slowestParse;\n    performanceScore += consistency * 10;\n    \n    return {\n      totalTests: profiles.length,\n      averageThroughput,\n      fastestParse,\n      slowestParse,\n      memoryEfficiency,\n      performanceScore: Math.min(performanceScore, 100)\n    };\n  };\n\n  // Get memory usage\n  const getMemoryUsage = (): number => {\n    if (typeof performance !== 'undefined' && (performance as any).memory) {\n      return (performance as any).memory.usedJSHeapSize / 1e6; // MB\n    }\n    if (typeof process !== 'undefined' && process.memoryUsage) {\n      return process.memoryUsage().heapUsed / 1e6; // MB\n    }\n    return 0;\n  };\n\n  // Export results\n  const exportResults = (format: 'json' | 'csv' | 'markdown' = 'json'): string => {\n    if (!currentProfile) return '';\n    \n    switch (format) {\n      case 'json':\n        return JSON.stringify({\n          profile: currentProfile,\n          history: benchmarkHistory,\n          report: performanceReport,\n          timestamp: new Date().toISOString()\n        }, null, 2);\n      \n      case 'csv':\n        const headers = ['Document Size', 'Parse Time', 'Throughput', 'Memory', 'Complexity', 'Headings', 'Links', 'Tables', 'Tasks', 'Math'];\n        const rows = benchmarkHistory.map(profile => [\n          profile.documentSize,\n          profile.parseTime.toFixed(3),\n          profile.throughput.toFixed(0),\n          profile.memory.toFixed(2),\n          profile.complexity,\n          profile.features.headings,\n          profile.features.links,\n          profile.features.tables,\n          profile.features.tasks,\n          profile.features.math\n        ]);\n        return [headers, ...rows].map(row => row.join(',')).join('\\n');\n      \n      case 'markdown':\n        return `# Performance Report\\n\\n## Current Profile\\n\\n- **Document Size**: ${(currentProfile.documentSize / 1024).toFixed(2)} KB\\n- **Parse Time**: ${currentProfile.parseTime.toFixed(3)} ms\\n- **Throughput**: ${currentProfile.throughput.toFixed(0)} chars/sec\\n- **Memory Usage**: ${currentProfile.memory.toFixed(2)} MB\\n- **Complexity**: ${currentProfile.complexity}\\n\\n## Features\\n\\n${Object.entries(currentProfile.features).map(([key, value]) => `- **${key}**: ${value}`).join('\\n')}\\n\\n## Recommendations\\n\\n${currentProfile.recommendations.map(rec => `- ${rec}`).join('\\n')}\\n\\n---\\n*Generated at ${new Date().toISOString()}*`;\n      \n      default:\n        return '';\n    }\n  };\n\n  // Clear history\n  const clearHistory = () => {\n    setBenchmarkHistory([]);\n    setCurrentProfile(null);\n    setPerformanceReport(null);\n  };\n\n  return {\n    isBenchmarking,\n    currentProfile,\n    benchmarkHistory,\n    performanceReport,\n    benchmark,\n    benchmarkSuite,\n    exportResults,\n    clearHistory,\n    getMemoryUsage\n  };\n}\n\n// Utility functions for performance testing\nexport const PerformanceUtils = {\n  // Generate test documents\n  generateTestDocuments: () => ({\n    small: `# Hi\\n**Bold** [link](https://bun.sh)`,\n    \n    medium: `## Medium\\n| A | B |\\n|---|---|\\n| 1 | 2 |\\n\\n- [ ] Task\\n- [x] Done\\n\\n$$x = 42$$`,\n    \n    large: `# Large Document\\n\\n${Array.from({ length: 100 }, (_, i) => \n      `## Section ${i + 1}\\n\\nThis is section ${i + 1} with various markdown features.\\n\\n### Features\\n\\n- [ ] Task ${i}\\n- [x] Completed ${i}\\n\\n| Feature | Status | Priority |\\n|---------|--------|----------|\\n| Item ${i} | Ready | ${i % 3 === 0 ? 'High' : 'Medium'} |\\n\\n**Bold text** and *italic text* with \\`code\\` blocks.\\n\\n[Link ${i}](https://example.com/${i})\\n\\n> **Quote ${i}**: This demonstrates performance with various elements.\\n\\n$$\\\\begin{equation}\\\\nx_{${i}} = \\\\sum_{k=1}^{${i}} k\\\\\\\\n\\\\end{equation}$$\\n\\n---\\n\\n`\n    ).join('\\n')}`\n  }),\n  \n  // Format profile for display\n  formatProfile: (profile: EnhancedProfile): Record<string, string> => ({\n    'Document Size': `${(profile.documentSize / 1024).toFixed(2)} KB`,\n    'Parse Time': `${profile.parseTime.toFixed(3)} ms`,\n    'Throughput': `${profile.throughput.toFixed(0)} chars/sec`,\n    'Memory Usage': `${profile.memory.toFixed(2)} MB`,\n    'Complexity': profile.complexity,\n    'Headings': profile.features.headings.toString(),\n    'Links': profile.features.links.toString(),\n    'Tables': profile.features.tables.toString(),\n    'Tasks': profile.features.tasks.toString(),\n    'Math Expressions': profile.features.math.toString()\n  }),\n  \n  // Calculate performance grade\n  calculateGrade: (profile: EnhancedProfile): 'A+' | 'A' | 'B' | 'C' | 'D' => {\n    const score = \n      (profile.parseTime < 1 ? 30 : profile.parseTime < 5 ? 20 : profile.parseTime < 10 ? 10 : 5) +\n      (profile.throughput > 50000 ? 30 : profile.throughput > 20000 ? 20 : profile.throughput > 10000 ? 10 : 5) +\n      (profile.memory < 10 ? 20 : profile.memory < 50 ? 15 : profile.memory < 100 ? 10 : 5) +\n      (profile.complexity === 'simple' ? 20 : profile.complexity === 'moderate' ? 15 : profile.complexity === 'complex' ? 10 : 5);\n    \n    if (score >= 90) return 'A+';\n    if (score >= 80) return 'A';\n    if (score >= 70) return 'B';\n    if (score >= 60) return 'C';\n    return 'D';\n  }\n};
