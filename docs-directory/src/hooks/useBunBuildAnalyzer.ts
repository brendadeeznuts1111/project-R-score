import { useState, useEffect } from 'react';\n\ninterface BunBuildMetafileOptions {\n  json?: string;\n  markdown?: string;\n}\n\ninterface BunBuildOptions {\n  entrypoints: string[];\n  outdir?: string;\n  outfile?: string;\n  metafile?: BunBuildMetafileOptions;\n  target?: 'browser' | 'node' | 'bun';\n  format?: 'esm' | 'cjs' | 'iife';\n  splitting?: boolean;\n  minify?: boolean;\n  sourcemap?: boolean;\n  external?: string[];\n  root?: string;\n  publicPath?: string;\n  define?: Record<string, string>;\n  plugins?: any[];\n}\n\ninterface BundleAnalysis {\n  summary: {\n    totalModules: number;\n    totalSize: number;\n    esmModules: number;\n    cjsModules: number;\n    outputToInputRatio: number;\n    largestModule: string;\n    largestModuleSize: number;\n  };\n  largestInputFiles: Array<{\n    path: string;\n    size: number;\n    percentage: number;\n  }>;\n  entryPoints: Array<{\n    entryPoint: string;\n    bundleSize: number;\n    exports: string[];\n    cssBundles: string[];\n    bundledModules: number;\n  }>;\\n  dependencyChains: {\n    mostCommonImports: Array<{ module: string; count: number; totalSize: number }>;\n    reverseDependencies: Record<string, string[]>;\n  };\n  moduleGraph: Array<{\n    path: string;\n    size: number;\n    imports: string[];\n    exports: string[];\n    dependents: string[];\n  }>;\n  rawMarkdown?: string;\n}\n\nexport function useBunBuildAnalyzer() {\n  const [isReady, setIsReady] = useState(false);\n  const [isAnalyzing, setIsAnalyzing] = useState(false);\n  const [currentAnalysis, setCurrentAnalysis] = useState<BundleAnalysis | null>(null);\n  const [analysisHistory, setAnalysisHistory] = useState<BundleAnalysis[]>([]);\n\n  useEffect(() => {\n    // Check if Bun build API is available\n    if (typeof Bun !== 'undefined' && Bun.build) {\n      setIsReady(true);\n    } else {\n      setIsReady(true); // Still allow manual analysis\n    }\n  }, []);\n\n  const analyzeBundle = async (\n    entrypoints: string[],\n    options: Partial<BunBuildOptions> = {}\n  ): Promise<BundleAnalysis> => {\n    setIsAnalyzing(true);\n    \n    try {\n      const buildOptions: BunBuildOptions = {\n        entrypoints,\n        outdir: './dist',\n        metafile: {\n          json: 'meta.json',\n          markdown: 'meta.md'\n        },\n        target: 'browser',\n        format: 'esm',\n        splitting: true,\n        minify: false, // Don't minify for analysis\n        sourcemap: true,\n        ...options\n      };\n\n      let metafileContent: string;\n      \n      if (typeof Bun !== 'undefined' && Bun.build) {\n        // Use Bun's build API with metafile\n        const result = await Bun.build(buildOptions);\n        \n        // Read the generated markdown metafile\n        const metafile = buildOptions.metafile?.markdown || 'meta.md';\n        const file = Bun.file(metafile);\n        metafileContent = await file.text();\n      } else {\n        // Fallback: simulate analysis for demo purposes\n        metafileContent = generateMockMetafile(entrypoints);\n      }\n      \n      const analysis = parseMetafileMarkdown(metafileContent);\n      analysis.rawMarkdown = metafileContent;\n      \n      setCurrentAnalysis(analysis);\n      setAnalysisHistory(prev => [...prev.slice(-9), analysis]); // Keep last 10\n      \n      return analysis;\n    } catch (error) {\n      console.error('Failed to analyze bundle:', error);\n      throw error;\n    } finally {\n      setIsAnalyzing(false);\n    }\n  };\n\n  const analyzeFromMetafile = async (metafilePath: string): Promise<BundleAnalysis> => {\n    setIsAnalyzing(true);\n    \n    try {\n      let metafileContent: string;\n      \n      if (typeof Bun !== 'undefined' && Bun.file) {\n        const file = Bun.file(metafilePath);\n        metafileContent = await file.text();\n      } else {\n        // Fallback for browser\n        const response = await fetch(metafilePath);\n        metafileContent = await response.text();\n      }\n      \n      const analysis = parseMetafileMarkdown(metafileContent);\n      analysis.rawMarkdown = metafileContent;\n      \n      setCurrentAnalysis(analysis);\n      setAnalysisHistory(prev => [...prev.slice(-9), analysis]);\n      \n      return analysis;\n    } catch (error) {\n      console.error('Failed to analyze metafile:', error);\n      throw error;\n    } finally {\n      setIsAnalyzing(false);\n    }\n  };\n\n  const generateOptimizationSuggestions = (analysis: BundleAnalysis): string[] => {\n    const suggestions: string[] = [];\n    \n    // Check for large modules\n    const largeModules = analysis.largestInputFiles.filter(file => file.percentage > 10);\n    if (largeModules.length > 0) {\n      suggestions.push(`Consider code splitting for large modules: ${largeModules.map(m => m.path).join(', ')}`);\n    }\n    \n    // Check output-to-input ratio\n    if (analysis.summary.outputToInputRatio > 2) {\n      suggestions.push('Bundle is significantly larger than inputs - check for duplicate dependencies');\n    }\n    \n    // Check for CommonJS modules\n    if (analysis.summary.cjsModules > 0) {\n      suggestions.push(`Consider converting ${analysis.summary.cjsModules} CommonJS modules to ESM for better tree-shaking`);\n    }\n    \n    // Check most common imports\n    const topImports = analysis.dependencyChains.mostCommonImports.slice(0, 3);\n    if (topImports.length > 0) {\n      suggestions.push(`Most imported modules: ${topImports.map(i => i.module).join(', ')} - consider optimizing imports`);\n    }\n    \n    return suggestions;\n  };\n\n  const exportAnalysis = (analysis: BundleAnalysis, format: 'json' | 'csv' | 'markdown' = 'json'): string => {\n    switch (format) {\n      case 'json':\n        return JSON.stringify(analysis, null, 2);\n      \n      case 'csv':\n        const headers = ['Module', 'Size (bytes)', 'Size (%)', 'Imports', 'Exports'];\n        const rows = analysis.moduleGraph.map(module => [\n          module.path,\n          module.size.toString(),\n          ((module.size / analysis.summary.totalSize) * 100).toFixed(2),\n          module.imports.length.toString(),\n          module.exports.length.toString()\n        ]);\n        return [headers, ...rows].map(row => row.join(',')).join('\\n');\n      \n      case 'markdown':\n        return analysis.rawMarkdown || '# No markdown data available';\n      \n      default:\n        return JSON.stringify(analysis, null, 2);\n    }\n  };\n\n  const clearHistory = () => {\n    setAnalysisHistory([]);\n  };\n\n  return {\n    isReady,\n    isAnalyzing,\n    currentAnalysis,\n    analysisHistory,\n    analyzeBundle,\n    analyzeFromMetafile,\n    generateOptimizationSuggestions,\n    exportAnalysis,\n    clearHistory\n  };\n}\n\nfunction parseMetafileMarkdown(markdown: string): BundleAnalysis {\n  const analysis: BundleAnalysis = {\n    summary: {\n      totalModules: 0,\n      totalSize: 0,\n      esmModules: 0,\n      cjsModules: 0,\n      outputToInputRatio: 0,\n      largestModule: '',\n      largestModuleSize: 0\n    },\n    largestInputFiles: [],\n    entryPoints: [],\n    dependencyChains: {\n      mostCommonImports: [],\n      reverseDependencies: {}\n    },\n    moduleGraph: []\n  };\n  \n  // Parse summary section\n  const summaryMatch = markdown.match(/## Quick Summary\\n\\n([\\s\\S]*?)(?=##|$)/);\n  if (summaryMatch) {\n    const summaryText = summaryMatch[1];\n    \n    const totalModulesMatch = summaryText.match(/Total modules: (\\d+)/);\n    if (totalModulesMatch) analysis.summary.totalModules = parseInt(totalModulesMatch[1]);\n    \n    const totalSizeMatch = summaryText.match(/Total size: ([\\d.]+) (KB|MB|GB)/);\n    if (totalSizeMatch) {\n      const size = parseFloat(totalSizeMatch[1]);\n      const unit = totalSizeMatch[2];\n      analysis.summary.totalSize = convertSizeToBytes(size, unit);\n    }\n    \n    const esmMatch = summaryText.match(/ESM modules: (\\d+)/);\n    if (esmMatch) analysis.summary.esmModules = parseInt(esmMatch[1]);\n    \n    const cjsMatch = summaryText.match(/CommonJS modules: (\\d+)/);\n    if (cjsMatch) analysis.summary.cjsModules = parseInt(cjsMatch[1]);\n    \n    const ratioMatch = summaryText.match(/Output\\/input ratio: ([\\d.]+)/);\n    if (ratioMatch) analysis.summary.outputToInputRatio = parseFloat(ratioMatch[1]);\n  }\n  \n  // Parse largest input files\n  const largestFilesMatch = markdown.match(/## Largest Input Files\\n\\n([\\s\\S]*?)(?=##|$)/);\n  if (largestFilesMatch) {\n    const filesText = largestFilesMatch[1];\n    const fileLines = filesText.split('\\n').filter(line => line.includes('['));\n    \n    fileLines.forEach(line => {\n      const pathMatch = line.match(/\\[([^\\]]+)\\]/);\n      const sizeMatch = line.match(/\\(([^)]+)\\)/);\n      \n      if (pathMatch && sizeMatch) {\n        const sizeText = sizeMatch[1];\n        const sizeMatch2 = sizeText.match(/([\\d.]+) (KB|MB|GB)/);\n        \n        if (sizeMatch2) {\n          const size = parseFloat(sizeMatch2[1]);\n          const unit = sizeMatch2[2];\n          const sizeBytes = convertSizeToBytes(size, unit);\n          \n          analysis.largestInputFiles.push({\n            path: pathMatch[1],\n            size: sizeBytes,\n            percentage: (sizeBytes / analysis.summary.totalSize) * 100\n          });\n        }\n      }\n    });\n  }\n  \n  // Parse module graph (simplified)\n  const moduleGraphMatch = markdown.match(/## Full Module Graph\\n\\n([\\s\\S]*?)(?=##|$)/);\n  if (moduleGraphMatch) {\n    const graphText = moduleGraphMatch[1];\n    const moduleLines = graphText.split('\\n').filter(line => line.startsWith('[MODULE:]'));\n    \n    moduleLines.forEach(line => {\n      const moduleMatch = line.match(/\\[MODULE:\\]([^\\s]+)/);\n      const sizeMatch = line.match(/\\[SIZE:\\]([\\d]+)/);\n      const importsMatch = line.match(/\\[IMPORTS:\\]([^\\s]+)/);\n      const exportsMatch = line.match(/\\[EXPORTS:\\]([^\\s]+)/);\n      \n      if (moduleMatch) {\n        analysis.moduleGraph.push({\n          path: moduleMatch[1],\n          size: sizeMatch ? parseInt(sizeMatch[1]) : 0,\n          imports: importsMatch ? importsMatch[1].split(',') : [],\n          exports: exportsMatch ? exportsMatch[1].split(',') : [],\n          dependents: []\n        });\n      }\n    });\n  }\n  \n  return analysis;\n}\n\nfunction convertSizeToBytes(size: number, unit: string): number {\n  switch (unit) {\n    case 'KB': return size * 1024;\n    case 'MB': return size * 1024 * 1024;\n    case 'GB': return size * 1024 * 1024 * 1024;\n    default: return size;\n  }\n}\n\nfunction generateMockMetafile(entrypoints: string[]): string {\n  const mockModules = [\n    'src/index.ts',\n    'src/components/Header.tsx',\n    'src/components/Footer.tsx',\n    'src/utils/helpers.ts',\n    'node_modules/react/index.js',\n    'node_modules/react-dom/index.js',\n    'node_modules/lodash/index.js'\n  ];\n  \n  let markdown = `# Bundle Analysis Report\\n\\n`;\n  markdown += `## Quick Summary\\n\\n`;\n  markdown += `- Total modules: ${mockModules.length}\\n`;\n  markdown += `- Total size: 2.5 MB\\n`;\n  markdown += `- ESM modules: ${mockModules.length - 2}\\n`;\n  markdown += `- CommonJS modules: 2\\n`;\n  markdown += `- Output/input ratio: 1.2\\n\\n`;\n  \n  markdown += `## Largest Input Files\\n\\n`;\n  markdown += `1. [node_modules/lodash/index.js] (800 KB)\\n`;\n  markdown += `2. [src/index.ts] (150 KB)\\n`;\n  markdown += `3. [src/components/Header.tsx] (100 KB)\\n\\n`;\n  \n  markdown += `## Full Module Graph\\n\\n`;\n  mockModules.forEach(module => {\n    const size = Math.floor(Math.random() * 100000) + 10000;\n    markdown += `[MODULE:]${module} [SIZE:]${size} [IMPORTS:]react,react-dom [EXPORTS:]default\\n`;\n  });\n  \n  return markdown;\n}\n\n// Utility function to format bytes\nexport function formatBytes(bytes: number): string {\n  if (bytes === 0) return '0 Bytes';\n  \n  const k = 1024;\n  const sizes = ['Bytes', 'KB', 'MB', 'GB'];\n  const i = Math.floor(Math.log(bytes) / Math.log(k));\n  \n  return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];\n}\n\n// Utility function to calculate bundle complexity score\nexport function calculateBundleComplexity(analysis: BundleAnalysis): number {\n  let score = 0;\n  \n  // Module count factor\n  score += Math.min(analysis.summary.totalModules / 100, 10);\n  \n  // Size factor\n  score += Math.min(analysis.summary.totalSize / (1024 * 1024), 10); // MB\n  \n  // Dependency complexity\n  score += Math.min(analysis.dependencyChains.mostCommonImports.length / 10, 5);\n  \n  // Mixed module types (ESM vs CJS)\n  if (analysis.summary.esmModules > 0 && analysis.summary.cjsModules > 0) {\n    score += 2;\n  }\n  \n  return Math.round(score);\n}
