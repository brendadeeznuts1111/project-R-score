name: Benchmark Suite

on:
  pull_request:
    paths:
      - 'packages/@graph/**'
      - 'packages/@bench/**'
      - 'packages/@dev/**'
  push:
    branches: [main]
    paths:
      - 'packages/@graph/**'
      - 'packages/@bench/**'
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
  workflow_dispatch:

env:
  BUN_CONFIG_DNS_TIME_TO_LIVE_SECONDS: 5

jobs:
  benchmark:
    name: Run Benchmarks
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Bun
        uses: oven/bun-action@v1
        with:
          bun-version: latest
      
      - name: Install dependencies
        run: bun install
        env:
          GRAPH_NPM_TOKEN: ${{ secrets.GRAPH_NPM_TOKEN }}
      
      - name: Run Layer4 benchmarks
        id: bench-layer4
        run: |
          echo "Running Layer4 property benchmarks..."
          cd packages/@bench/layer4
          bun run bench || BENCH_EXIT=$?
          echo "bench_exit=${BENCH_EXIT:-0}" >> $GITHUB_OUTPUT
      
      - name: Upload benchmark results
        if: always()
        run: |
          echo "Uploading benchmark results to private registry..."
          # Results are automatically uploaded by @bench/core
        env:
          GRAPH_NPM_TOKEN: ${{ secrets.GRAPH_NPM_TOKEN }}
      
      - name: Check for regressions
        id: check-regressions
        run: |
          echo "Checking for performance regressions..."
          # Regression checking is handled by @bench/core
        env:
          GRAPH_NPM_TOKEN: ${{ secrets.GRAPH_NPM_TOKEN }}
      
      - name: Comment PR with benchmark results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const benchExit = '${{ steps.bench-layer4.outputs.bench_exit }}' === '0';
            const regressionsExit = '${{ steps.check-regressions.outputs.regressions_exit }}' === '0';
            
            const allPassed = benchExit && regressionsExit;
            const emoji = allPassed ? '✅' : '⚠️';
            const status = allPassed ? 'All benchmarks passed' : 'Benchmarks completed with issues';
            
            const comment = `## ${emoji} Benchmark Results: Layer4 Property Iteration
            
            **Status**: ${status}
            
            - **Benchmark Execution**: ${benchExit ? '✅ Passed' : '❌ Failed'}
            - **Regression Check**: ${regressionsExit ? '✅ No regressions' : '⚠️ Regressions detected'}
            
            ${allPassed ? '✅ All benchmarks passed successfully!' : '⚠️ Please review benchmark results above.'}
            
            See benchmark output above for detailed results.`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
      
      - name: Fail on benchmark failure
        if: steps.bench-layer4.outputs.bench_exit != '0'
        run: |
          echo "❌ Benchmark failures detected!"
          exit 1
