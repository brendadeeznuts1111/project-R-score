---
name: bench
description: "Use when user wants to benchmark scripts, measure performance, compare timings, or run performance tests: iterations, warmup, cold/hot cache, stats, comparison"
user-invocable: true
version: 1.0.0
---

# /bench - Performance Benchmark Harness

Run performance benchmarks on scripts with statistical analysis.

## Implementation

Execute the benchmark harness:

```bash
bun ~/.claude/scripts/bench.ts [script] [options]
```

## Quick Reference

- **`/bench`** â€” Run enterprise benchmark suite (default)
- **`/bench --suite --report`** â€” Suite with HTML report
- **`/bench --suite --check 10`** â€” CI: fail if >10% regression
- **`/bench --suite --json`** â€” JSON output for pipelines
- **`/bench matrix`** â€” Benchmark single script
- **`/bench matrix -n 10`** â€” Run 10 iterations
- **`/bench --list`** â€” List available scripts
- **`/bench matrix --save`** â€” Save result to JSON
- **`/bench matrix --compare baseline.json`** â€” Compare to baseline
- **`/bench matrix --histogram`** â€” Show timing distribution
- **`/bench matrix --history`** â€” Show historical trends
- **`/bench matrix --check 5`** â€” CI mode: fail on >5% regression
- **`/bench matrix --watch`** â€” Live mode: continuous benchmarking
- **`/bench matrix -i`** â€” Interactive baseline selection

## Options

### Suite Mode (default)

- **`--suite`** â€” Run all core benchmarks with dashboard
- **`--report`** â€” Generate HTML report
- **`--check [N]`** â€” CI mode: exit 1 if any script > N% (default: 10%)
- **`--json`** â€” Output suite results as JSON
- **`-n, --iterations`** â€” Iterations per script (default: 3)
- **`-w, --warmup`** â€” Warmup runs per script (default: 1)

### Single Script Mode

- **`-n, --iterations`** â€” Number of timed runs (default: 5)
- **`-w, --warmup`** â€” Number of warmup runs (default: 2)
- **`--save`** â€” Save result to JSON file
- **`--compare <file>`** â€” Compare against baseline
- **`--json`** â€” Output JSON only
- **`--histogram`** â€” Show timing distribution histogram
- **`--history`** â€” Show historical benchmark trends
- **`--check [N]`** â€” CI mode: exit 1 if regression > N% (default: 5%)
- **`--no-record`** â€” Don't save to history database
- **`--watch [N]`** â€” Live mode: benchmark every N ms (default: 2000)
- **`-i, --interactive`** â€” Select baseline from history

## Statistics Reported

- **Min** â€” Fastest run time
- **Max** â€” Slowest run time
- **Mean** â€” Average run time
- **Median** â€” Middle run time
- **Std Dev** â€” Timing variability
- **P95** â€” 95th percentile
- **Cold** â€” First run (no JIT/cache)

## Memory Profile

- **Peak Heap** â€” Maximum heap memory used
- **Current Heap** â€” Heap memory at end of run
- **Freed** â€” Memory reclaimed during run
- **Heap Total** â€” Total heap size allocated
- **External** â€” Memory used by C++ objects
- **RSS (Peak)** â€” Peak resident set size

## Hotpath & Cache Handling

The harness handles JIT optimization and filesystem caching:

1. **Cold run** - Measured before any warmup (captures startup cost)
2. **Warmup runs** - Prime JIT compiler and filesystem cache (not timed)
3. **Timed runs** - Post-warmup with GC between runs

## Comparison Verdicts

- **:rocket: FASTER** â€” >5% improvement
- **:turtle: SLOWER** â€” >5% regression
- **:arrow_right: UNCHANGED** â€” +/-5%

## Enterprise Dashboard

Running `/bench` without arguments launches the enterprise suite:

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  ðŸ¢ ENTERPRISE BENCHMARK SUITE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  ðŸ“‹ Scripts: 5
  ðŸ”„ Iterations: 3 (+ 1 warmup)
  ðŸ–¥ï¸  System: Apple M4
  ðŸ“¦ Bun: v1.3.6

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ðŸ“Š BENCHMARK DASHBOARD

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Status â”‚ Script       â”‚ Median â”‚ Change â”‚ Trend â”‚ Health   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ…     â”‚ matrix       â”‚ 1.52s  â”‚ -2.1%  â”‚ â–ƒâ–„â–…â–„â–ƒ â”‚ GOOD     â”‚
â”‚ ðŸš€     â”‚ quick-wins   â”‚ 180ms  â”‚ -12.5% â”‚ â–…â–„â–ƒâ–‚â– â”‚ EXCELLENTâ”‚
â”‚ âž¡ï¸     â”‚ quick-wins-2 â”‚ 115ms  â”‚ +0.8%  â”‚ â–„â–„â–„â–„â–„ â”‚ STABLE   â”‚
â”‚ âš ï¸     â”‚ quick-wins-3 â”‚ 620ms  â”‚ +8.2%  â”‚ â–‚â–ƒâ–„â–…â–† â”‚ WARNING  â”‚
â”‚ ðŸ†•     â”‚ quick-wins-4 â”‚ 880ms  â”‚ -      â”‚ -     â”‚ NEW      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Health Statuses

- **ðŸš€ EXCELLENT** â€” >10% faster
- **âœ… GOOD** â€” 5-10% faster
- **âž¡ï¸ STABLE** â€” +/-5%
- **âš ï¸ WARNING** â€” 5-15% slower
- **ðŸ”´ CRITICAL** â€” >15% slower
- **ðŸ†• NEW** â€” No baseline

### CI/CD Integration

```bash
# GitHub Actions / CI pipelines
bun bench.ts --suite --check 10    # Fail if >10% regression
bun bench.ts --suite --json        # JSON for artifacts
bun bench.ts --suite --report      # HTML report
```

## Available Scripts

- **`matrix`** â€” Lockfile health matrix scanner
- **`lockfile-matrix`** â€” Alias for matrix
- **`quick-wins`** â€” Quick Wins Round 1 - Matrix column optimizations (#1-4)
- **`quick-wins-1`** â€” Alias for quick-wins
- **`buffer-includes`** â€” Buffer.indexOf/includes SIMD (99,999 runs, 44.5KB)
- **`spawn-sync`** â€” Bun.spawnSync close_range fix (100 spawns, Linux)

## Recent Benchmark Standards (Tier-1380)

| API | Baseline | Standard |
|-----|----------|----------|
| Buffer.indexOf / Buffer.includes | SIMD 2x | 99,999 runs, 44.5KB buffer; .includes true ~22ms, .includes false ~1.4s |
| Bun.spawnSync | close_range 30x | 100Ã— `Bun.spawnSync(["true"])`; Linux ~0.4ms, legacy ~13ms |

## CPU/Heap Profiling (Bun 1.3.7+)

Generate detailed profiling reports with markdown output for LLM analysis:

```bash
# CPU profile only (markdown format)
bun --cpu-prof-md script.ts

# CPU profile (both JSON + markdown)
bun --cpu-prof --cpu-prof-md script.ts

# Full profiling (CPU + heap)
bun --cpu-prof --cpu-prof-md --heap-prof --heap-prof-md script.ts

# Custom output location
bun --cpu-prof --cpu-prof-md --cpu-prof-dir=./profiles --cpu-prof-name=my-profile script.ts

# Using the profile helper
bun ~/.claude/benchmarks/scripts/profile-md.ts <script> [name]
```

### Profile Output Format

The markdown profile includes:
- **Top 10 hot functions** with self-time percentages
- **Call tree** with hierarchical execution flow
- **Function details** with caller/callee relationships
- **File breakdown** showing time spent per source file

### Profile Flags Reference

- **`--cpu-prof`** â€” Generate Chrome DevTools JSON profile
- **`--cpu-prof-md`** â€” Generate markdown CPU profile (LLM-friendly)
- **`--cpu-prof-name=<name>`** â€” Custom profile filename
- **`--cpu-prof-dir=<dir>`** â€” Output directory
- **`--heap-prof`** â€” Generate V8 heap snapshot
- **`--heap-prof-md`** â€” Generate markdown heap profile

### Grep Patterns for Profile Analysis

```bash
# CPU Profile (markdown)
grep '| .* | `' profile.md              # All function entries
grep -E '\| [5-9][0-9]\.[0-9]%' profile.md  # Functions using >50% time
grep 'Self:.*Total:' profile.md         # Function details section

# Heap Profile (markdown)
grep 'type=Function' profile.md         # Find all Function objects
grep 'size=[0-9]\{5,\}' profile.md      # Find objects >= 10KB
grep 'gcroot=1' profile.md              # Find all GC roots
grep 'type=Array' profile.md            # Find all arrays
grep 'retainers=' profile.md            # Objects with retention info
```

## Adding New Scripts

Edit `~/.claude/scripts/bench.ts` and add to `BENCHMARKABLE_SCRIPTS`:

```typescript
const BENCHMARKABLE_SCRIPTS = {
  "my-script": {
    file: "my-script.ts",
    args: ["--quiet"],
    description: "Description of script",
  },
};
```
