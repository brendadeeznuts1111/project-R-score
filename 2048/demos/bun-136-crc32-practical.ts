#!/usr/bin/env bun

// Practical demonstration of Bun v1.3.6 Hardware-Accelerated CRC32
console.log("‚ö° Practical CRC32 Performance with Hardware Acceleration");
console.log("=".repeat(55));

import { performance } from "node:perf_hooks";

// Test 1: Basic CRC32 Performance
console.log("\n1Ô∏è‚É£ Basic CRC32 Performance Test:");

async function testBasicCRC32Performance() {
  console.log("‚úÖ Testing hardware-accelerated CRC32 with various data sizes");

  const sizes = [
    { name: "1KB", bytes: 1024 },
    { name: "10KB", bytes: 1024 * 10 },
    { name: "100KB", bytes: 1024 * 100 },
    { name: "1MB", bytes: 1024 * 1024 },
    { name: "10MB", bytes: 1024 * 1024 * 10 },
  ];

  for (const size of sizes) {
    const data = Buffer.alloc(size.bytes);
    const iterations = 1000;

    // Warm up
    for (let i = 0; i < 10; i++) {
      Bun.hash.crc32(data);
    }

    // Benchmark
    const startTime = performance.now();

    for (let i = 0; i < iterations; i++) {
      Bun.hash.crc32(data);
    }

    const endTime = performance.now();
    const totalTime = endTime - startTime;
    const throughput =
      (size.bytes * iterations) / (totalTime / 1000) / 1024 / 1024;

    console.log(
      `   üìä ${size.name} (${size.bytes} bytes): ${throughput.toFixed(2)} MB/s`,
    );
  }
}

// Test 2: Real-World CRC32 Use Cases
console.log("\n2Ô∏è‚É£ Real-World CRC32 Use Cases:");

class FastCRC32Processor {
  // File integrity checking
  async calculateFileCRC32(
    filePath: string,
  ): Promise<{ hash: number; time: number }> {
    const startTime = performance.now();

    try {
      const file = Bun.file(filePath);
      const buffer = await file.arrayBuffer();
      const hash = Bun.hash.crc32(Buffer.from(buffer));

      const endTime = performance.now();
      const time = endTime - startTime;

      return { hash, time };
    } catch (error) {
      console.error(`   ‚ùå Error reading file ${filePath}:`, error);
      return { hash: 0, time: 0 };
    }
  }

  // Data streaming CRC32
  calculateStreamingCRC32(chunks: Buffer[]): { hash: number; time: number } {
    const startTime = performance.now();

    let combinedHash = 0;
    for (const chunk of chunks) {
      const chunkHash = Bun.hash.crc32(chunk);
      combinedHash ^= chunkHash; // Simple combination
    }

    const endTime = performance.now();
    const time = endTime - startTime;

    return { hash: combinedHash, time };
  }

  // Database record hashing
  calculateRecordCRC32(record: Record<string, any>): {
    hash: number;
    time: number;
  } {
    const startTime = performance.now();

    const sortedKeys = Object.keys(record).sort();
    const serialized = JSON.stringify(record, sortedKeys);
    const hash = Bun.hash.crc32(Buffer.from(serialized));

    const endTime = performance.now();
    const time = endTime - startTime;

    return { hash, time };
  }

  // Performance comparison
  async comparePerformance(dataSize: number): Promise<void> {
    const data = Buffer.alloc(dataSize);
    const iterations = 1000;

    console.log(`   üìä Performance test with ${dataSize} bytes data:`);

    // Test Bun.hash.crc32 (hardware accelerated)
    const hwStart = performance.now();
    for (let i = 0; i < iterations; i++) {
      Bun.hash.crc32(data);
    }
    const hwTime = performance.now() - hwStart;

    // Test with a simple software implementation for comparison
    const swStart = performance.now();
    for (let i = 0; i < iterations; i++) {
      // Simple software CRC32 simulation (slower)
      let hash = 0;
      for (let j = 0; j < Math.min(data.length, 100); j++) {
        hash = ((hash << 8) ^ data[j]) & 0xffffffff;
      }
    }
    const swTime = performance.now() - swStart;

    const speedup = swTime / hwTime;

    console.log(`      Hardware CRC32: ${hwTime.toFixed(2)}ms`);
    console.log(`      Software CRC32: ${swTime.toFixed(2)}ms`);
    console.log(`      üöÄ Speedup: ${speedup.toFixed(2)}x faster!`);
  }
}

async function testRealWorldUseCases() {
  const processor = new FastCRC32Processor();

  console.log("‚úÖ File integrity checking");

  // Test with package.json (existing file)
  const packageResult = await processor.calculateFileCRC32("package.json");
  if (packageResult.hash > 0) {
    console.log(
      `   üìÑ package.json CRC32: ${packageResult.hash.toString(16)} (${packageResult.time.toFixed(2)}ms)`,
    );
  }

  console.log("‚úÖ Data streaming CRC32");

  // Test streaming data
  const chunks = [
    Buffer.from("This is chunk 1 of streaming data"),
    Buffer.from("This is chunk 2 with more content"),
    Buffer.from("Final chunk with streaming test data"),
  ];

  const streamResult = processor.calculateStreamingCRC32(chunks);
  console.log(
    `   üì¶ Streaming data CRC32: ${streamResult.hash.toString(16)} (${streamResult.time.toFixed(2)}ms)`,
  );

  console.log("‚úÖ Database record hashing");

  // Test database record
  const record = {
    id: 12345,
    name: "test-record",
    email: "test@example.com",
    data: "large data field content",
    timestamp: new Date().toISOString(),
  };

  const recordResult = processor.calculateRecordCRC32(record);
  console.log(
    `   üóÉÔ∏è  Database record CRC32: ${recordResult.hash.toString(16)} (${recordResult.time.toFixed(2)}ms)`,
  );

  console.log("‚úÖ Performance comparison");

  // Performance comparison with different data sizes
  await processor.comparePerformance(1024 * 1024); // 1MB
}

// Test 3: Integration Examples
console.log("\n3Ô∏è‚É£ Integration Examples:");

function demonstrateIntegrationExamples() {
  console.log("‚úÖ Seamless integration with existing code");

  // Example 1: Data validation
  function validateDataIntegrity(
    originalData: Buffer,
    receivedData: Buffer,
  ): boolean {
    const originalHash = Bun.hash.crc32(originalData);
    const receivedHash = Bun.hash.crc32(receivedData);
    return originalHash === receivedHash;
  }

  // Example 2: Cache key generation
  function generateCacheKey(data: Record<string, any>): string {
    const hash = Bun.hash.crc32(Buffer.from(JSON.stringify(data)));
    return `cache_${hash.toString(16)}`;
  }

  // Example 3: Content deduplication
  class ContentDeduplicator {
    private contentHashes = new Map<number, string>();

    addContent(content: string): string {
      const hash = Bun.hash.crc32(Buffer.from(content));

      if (this.contentHashes.has(hash)) {
        return this.contentHashes.get(hash)!;
      }

      const id = `content_${this.contentHashes.size + 1}`;
      this.contentHashes.set(hash, id);
      return id;
    }
  }

  // Demonstrate usage
  const testData = Buffer.from("test data for integrity check");
  const modifiedData = Buffer.from("test data for integrity check");
  const corruptedData = Buffer.from("test data for integrity check!");

  console.log(
    `   üîç Data integrity check: ${validateDataIntegrity(testData, modifiedData)}`,
  );
  console.log(
    `   ‚ùå Corrupted data detected: ${!validateDataIntegrity(testData, corruptedData)}`,
  );

  const cacheData = {
    user: "john",
    page: "dashboard",
    filters: ["active", "recent"],
  };
  const cacheKey = generateCacheKey(cacheData);
  console.log(`   üóùÔ∏è  Cache key: ${cacheKey}`);

  const deduplicator = new ContentDeduplicator();
  const content1 = deduplicator.addContent("duplicate content");
  const content2 = deduplicator.addContent("duplicate content");
  const content3 = deduplicator.addContent("unique content");

  console.log(`   üîÑ Deduplication: ${content1 === content2} (same content)`);
  console.log(
    `   üîÑ Unique content: ${content2 !== content3} (different content)`,
  );
}

// Test 4: Performance Impact Analysis
console.log("\n4Ô∏è‚É£ Performance Impact Analysis:");

async function analyzePerformanceImpact() {
  console.log("‚úÖ Measuring real-world performance improvements");

  // Simulate a data processing pipeline
  class DataProcessor {
    async processData(
      data: Buffer[],
    ): Promise<{ processed: number; totalTime: number }> {
      const startTime = performance.now();
      let processed = 0;

      for (const chunk of data) {
        // Simulate processing with CRC32 for integrity
        const hash = Bun.hash.crc32(chunk);

        // Simulate some processing work
        await new Promise((resolve) => setTimeout(resolve, 1));

        processed++;
      }

      const endTime = performance.now();
      return { processed, totalTime: endTime - startTime };
    }
  }

  const processor = new DataProcessor();

  // Generate test data
  const testData = Array.from({ length: 100 }, (_, i) =>
    Buffer.from(`data chunk ${i} with some content to process`),
  );

  console.log(`   üìä Processing ${testData.length} data chunks...`);

  const result = await processor.processData(testData);
  const avgTimePerChunk = result.totalTime / result.processed;

  console.log(
    `   ‚úÖ Processed ${result.processed} chunks in ${result.totalTime.toFixed(2)}ms`,
  );
  console.log(`   üìà Average time per chunk: ${avgTimePerChunk.toFixed(2)}ms`);
  console.log(
    `   üöÄ Hardware acceleration makes CRC32 negligible in processing time`,
  );
}

// Main demonstration function
async function main() {
  try {
    await testBasicCRC32Performance();
    await testRealWorldUseCases();
    demonstrateIntegrationExamples();
    await analyzePerformanceImpact();

    console.log("\nüéØ Hardware-Accelerated CRC32 Benefits:");
    console.log(
      "   ‚ö° ~20x faster performance with PCLMULQDQ/ARM instructions",
    );
    console.log("   üîß zlib-based implementation for optimal performance");
    console.log("   üìä Significant speedup on large data buffers");
    console.log("   üîÑ Drop-in replacement with zero code changes");
    console.log(
      "   üíº Perfect for file integrity, databases, and network protocols",
    );
    console.log(
      "   üöÄ Makes CRC32 operations virtually free in performance terms",
    );

    console.log("\nüí® Your CRC32 operations are now lightning fast!");
  } catch (error) {
    console.error("‚ùå Demonstration failed:", error);
  }
}

if (import.meta.main) {
  main();
}

export { FastCRC32Processor, main as demonstrateCRC32Performance };
