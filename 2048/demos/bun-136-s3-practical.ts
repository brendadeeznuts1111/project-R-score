#!/usr/bin/env bun

// Practical demonstration of Bun v1.3.6 S3 Requester Pays Support
console.log("‚òÅÔ∏è  Bun v1.3.6 S3 Requester Pays Support - Practical Demo");
console.log("=".repeat(58));

// Test 1: Basic S3 Requester Pays Operations
async function demonstrateBasicOperations() {
  console.log("\n1Ô∏è‚É£ Basic S3 Requester Pays Operations:");

  console.log("   ‚úÖ Simple requestPayer: true option");
  console.log("   üîß Works with reading, writing, and metadata operations");
  console.log("   üöÄ No additional configuration required");

  const basicCode = `
// v1.3.6: Basic S3 Requester Pays operations
import { s3 } from "bun";

// Reading from a Requester Pays bucket
async function readFromRequesterPaysBucket(key: string, bucket: string) {
  try {
    const file = s3.file(key, {
      bucket: bucket,
      requestPayer: true  // Enable Requester Pays
    });

    const content = await file.text();
    console.log(\`Read \${content.length} bytes from \${bucket}/\${key}\`);

    return content;
  } catch (error) {
    console.error('Failed to read from Requester Pays bucket:', error);
    throw error;
  }
}

// Writing to a Requester Pays bucket
async function writeToRequesterPaysBucket(
  key: string,
  data: string,
  bucket: string
) {
  try {
    await s3.write(key, data, {
      bucket: bucket,
      requestPayer: true  // Enable Requester Pays
    });

    console.log(\`Wrote \${data.length} bytes to \${bucket}/\${key}\`);
  } catch (error) {
    console.error('Failed to write to Requester Pays bucket:', error);
    throw error;
  }
}

// Getting file stats from Requester Pays bucket
async function getStatsFromRequesterPaysBucket(key: string, bucket: string) {
  try {
    const stats = await s3.stat(key, {
      bucket: bucket,
      requestPayer: true  // Enable Requester Pays
    });

    console.log(\`File stats for \${bucket}/\${key}:\`);
    console.log(\`  Size: \${stats.size} bytes\`);
    console.log(\`  Last modified: \${stats.lastModified}\`);
    console.log(\`  Content type: \${stats.contentType}\`);

    return stats;
  } catch (error) {
    console.error('Failed to get stats from Requester Pays bucket:', error);
    throw error;
  }
}

// Usage examples
const BUCKET = "public-research-dataset";
const DATA_KEY = "research-data.csv";
const RESULTS_KEY = "analysis-results.json";

// Read public research data
const researchData = await readFromRequesterPaysBucket(DATA_KEY, BUCKET);

// Process data and upload results
const analysisResults = JSON.stringify({
  processed: true,
  recordCount: researchData.split('\\n').length,
  timestamp: new Date().toISOString()
});

await writeToRequesterPaysBucket(RESULTS_KEY, analysisResults, BUCKET);

// Get file information
const stats = await getStatsFromRequesterPaysBucket(DATA_KEY, BUCKET);
  `;

  console.log("   üí° Basic operations implementation:");
  console.log(basicCode);
}

// Test 2: Multipart Uploads with Requester Pays
async function demonstrateMultipartUploads() {
  console.log("\n2Ô∏è‚É£ Multipart Uploads with Requester Pays:");

  console.log("   ‚úÖ Large file uploads with Requester Pays support");
  console.log("   üîß Efficient chunked uploads for cost optimization");
  console.log("   üöÄ Automatic error recovery and retry logic");

  const multipartCode = `
// v1.3.6: Multipart uploads with Requester Pays
import { s3 } from "bun";

class S3RequesterPaysUploader {
  private bucket: string;

  constructor(bucket: string) {
    this.bucket = bucket;
  }

  async uploadLargeFile(key: string, data: Buffer): Promise<void> {
    console.log(\`Starting upload of \${data.length} bytes to \${this.bucket}/\${key}\`);

    try {
      const upload = s3.upload({
        bucket: this.bucket,
        key: key,
        requestPayer: true  // Enable Requester Pays
      });

      // Upload in 5MB chunks for optimal performance
      const chunkSize = 5 * 1024 * 1024;
      let uploadedBytes = 0;

      for (let i = 0; i < data.length; i += chunkSize) {
        const chunk = data.subarray(i, i + chunkSize);

        await upload.write(chunk);
        uploadedBytes += chunk.length;

        console.log(\`Uploaded \${uploadedBytes}/\${data.length} bytes (\${Math.round(uploadedBytes / data.length * 100)}%)\`);
      }

      await upload.end();
      console.log(\`Upload completed: \${this.bucket}/\${key}\`);

    } catch (error) {
      console.error('Multipart upload failed:', error);
      throw error;
    }
  }

  async uploadWithRetry(key: string, data: Buffer, maxRetries: number = 3): Promise<void> {
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        await this.uploadLargeFile(key, data);
        return; // Success
      } catch (error) {
        console.log(\`Upload attempt \${attempt} failed:\`, error.message);

        if (attempt === maxRetries) {
          throw error; // All retries exhausted
        }

        // Exponential backoff
        const delay = Math.pow(2, attempt) * 1000;
        console.log(\`Retrying in \${delay}ms...\`);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }
}

// Usage example
const uploader = new S3RequesterPaysUploader("research-data-bucket");

// Create a large dataset (simulated)
const largeDataset = JSON.stringify({
  data: Array.from({ length: 100000 }, (_, i) => ({
    id: i,
    value: Math.random(),
    timestamp: Date.now()
  }))
});

const dataBuffer = Buffer.from(largeDataset);

// Upload with retry logic
await uploader.uploadWithRetry("large-dataset.json", dataBuffer);
  `;

  console.log("   üí° Multipart upload implementation:");
  console.log(multipartCode);
}

// Test 3: Cost Tracking and Management
async function demonstrateCostTracking() {
  console.log("\n3Ô∏è‚É£ Cost Tracking and Management:");

  console.log("   ‚úÖ Monitor Requester Pays costs in real-time");
  console.log("   üîß Track requests and data transfer volumes");
  console.log("   üöÄ Generate cost reports and alerts");

  const costTrackingCode = `
// v1.3.6: Cost tracking for Requester Pays buckets
import { s3 } from "bun";

interface CostMetrics {
  requests: number;
  bytesTransferred: number;
  estimatedCost: number;
}

class S3RequesterPaysCostTracker {
  private metrics = new Map<string, CostMetrics>();
  private readonly COST_PER_REQUEST = 0.0004; // $0.0004 per 1,000 requests
  private readonly COST_PER_GB = 0.09; // $0.09 per GB transfer

  async trackOperation<T>(
    operation: string,
    bucket: string,
    operationFn: () => Promise<T>
  ): Promise<T> {
    const startTime = Date.now();
    let bytesTransferred = 0;

    try {
      const result = await operationFn();

      // Update metrics
      const current = this.metrics.get(bucket) || { requests: 0, bytesTransferred: 0, estimatedCost: 0 };
      current.requests += 1;
      current.bytesTransferred += bytesTransferred;
      current.estimatedCost = this.calculateCost(current.requests, current.bytesTransferred);

      this.metrics.set(bucket, current);

      console.log(\`\${operation} completed for \${bucket} in \${Date.now() - startTime}ms\`);
      return result;

    } catch (error) {
      console.error(\`\${operation} failed for \${bucket}:\`, error);
      throw error;
    }
  }

  async readFileWithTracking(key: string, bucket: string): Promise<string> {
    return this.trackOperation(\`readFile:\${key}\`, bucket, async () => {
      const file = s3.file(key, { bucket, requestPayer: true });
      const content = await file.text();

      // Track bytes transferred
      this.updateBytesTransferred(bucket, content.length);

      return content;
    });
  }

  async writeFileWithTracking(key: string, data: string | Buffer, bucket: string): Promise<void> {
    return this.trackOperation(\`writeFile:\${key}\`, bucket, async () => {
      await s3.write(key, data, { bucket, requestPayer: true });

      // Track bytes transferred
      const bytes = typeof data === 'string' ? data.length : data.length;
      this.updateBytesTransferred(bucket, bytes);
    });
  }

  private updateBytesTransferred(bucket: string, bytes: number): void {
    const current = this.metrics.get(bucket) || { requests: 0, bytesTransferred: 0, estimatedCost: 0 };
    current.bytesTransferred += bytes;
    current.estimatedCost = this.calculateCost(current.requests, current.bytesTransferred);
    this.metrics.set(bucket, current);
  }

  private calculateCost(requests: number, bytes: number): number {
    const requestCost = (requests / 1000) * this.COST_PER_REQUEST;
    const transferCost = (bytes / 1024 / 1024 / 1024) * this.COST_PER_GB;
    return requestCost + transferCost;
  }

  getCostReport(): Record<string, CostMetrics> {
    const report: Record<string, CostMetrics> = {};

    for (const [bucket, metrics] of this.metrics) {
      report[bucket] = { ...metrics };
    }

    return report;
  }

  getTotalCost(): number {
    let total = 0;
    for (const metrics of this.metrics.values()) {
      total += metrics.estimatedCost;
    }
    return total;
  }

  checkBudgetAlert(budget: number): void {
    const total = this.getTotalCost();

    if (total > budget) {
      console.warn(\`üö® BUDGET ALERT: Current cost $\${total.toFixed(4)} exceeds budget $\${budget.toFixed(4)}\`);
    } else {
      console.log(\`‚úÖ Cost within budget: $\${total.toFixed(4)} / $\${budget.toFixed(4)}\`);
    }
  }
}

// Usage example
const costTracker = new S3RequesterPaysCostTracker();
const BUDGET = 10.00; // $10 budget

// Track various operations
await costTracker.readFileWithTracking("dataset.csv", "public-research-bucket");
await costTracker.writeFileWithTracking("results.json", analysisData, "public-research-bucket");
await costTracker.readFileWithTracking("config.json", "shared-config-bucket");

// Generate cost report
console.log("Cost Report:", costTracker.getCostReport());
console.log(\`Total Cost: $\${costTracker.getTotalCost().toFixed(4)}\`);

// Check budget
costTracker.checkBudgetAlert(BUDGET);
  `;

  console.log("   üí° Cost tracking implementation:");
  console.log(costTrackingCode);
}

// Test 4: Real-world Use Cases
async function demonstrateRealWorldUseCases() {
  console.log("\n4Ô∏è‚É£ Real-world Use Cases:");

  const useCases = [
    {
      title: "Research Data Access",
      description: "Accessing large public research datasets",
      code: `
// Research data analysis
const researchClient = new S3RequesterPaysClient("covid-19-dataset");
const genomeData = await researchClient.readFile("genome-sequences.fasta");
const analysisResults = analyzeGenomeData(genomeData);
await researchClient.writeFile("analysis-results.json", JSON.stringify(analysisResults));
      `,
    },
    {
      title: "Educational Content",
      description: "Universities sharing educational resources",
      code: `
// Educational platform
const eduClient = new S3RequesterPaysClient("university-open-courses");
const courseMaterials = await eduClient.readFile("cs101-lecture-notes.pdf");
const studentSubmissions = await eduClient.listFiles("submissions/");
      `,
    },
    {
      title: "Media Distribution",
      description: "Media companies distributing content to partners",
      code: `
// Media distribution
const mediaClient = new S3RequesterPaysClient("media-archive");
const videoMetadata = await mediaClient.readFile("video-library/metadata.json");
await mediaClient.uploadLargeFile("new-content/video.mp4", videoBuffer);
      `,
    },
    {
      title: "Government Open Data",
      description: "Government agencies providing public data access",
      code: `
// Government data portal
const govClient = new S3RequesterPaysClient("gov-open-data");
const censusData = await govClient.readFile("census-2020/demographics.csv");
const processedData = processCensusData(censusData);
await govClient.writeFile("processed/summary-stats.json", processedData);
      `,
    },
  ];

  useCases.forEach((useCase, index) => {
    console.log(`\n   ${index + 1}. ${useCase.title}:`);
    console.log(`      Description: ${useCase.description}`);
    console.log(`      Code example:`);
    console.log(useCase.code);
  });
}

// Test 5: Error Handling and Best Practices
async function demonstrateErrorHandling() {
  console.log("\n5Ô∏è‚É£ Error Handling and Best Practices:");

  const bestPractices = [
    {
      practice: "Validate bucket access",
      code: `
// Check bucket access before operations
async function validateBucketAccess(bucket: string): Promise<boolean> {
  try {
    await s3.stat("access-check", { bucket, requestPayer: true });
    return true;
  } catch (error) {
    console.error(\`Bucket access validation failed for \${bucket}:\`, error);
    return false;
  }
}
      `,
    },
    {
      practice: "Implement retry logic",
      code: `
// Retry with exponential backoff
async function retryOperation<T>(
  operation: () => Promise<T>,
  maxRetries: number = 3
): Promise<T> {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      return await operation();
    } catch (error) {
      if (attempt === maxRetries) throw error;
      await new Promise(resolve => setTimeout(resolve, Math.pow(2, attempt) * 1000));
    }
  }
}
      `,
    },
    {
      practice: "Monitor costs continuously",
      code: `
// Continuous cost monitoring
setInterval(() => {
  const report = costTracker.getCostReport();
  const total = costTracker.getTotalCost();

  if (total > COST_THRESHOLD) {
    console.warn(\`Cost threshold exceeded: $\${total.toFixed(4)}\`);
    // Send alert or stop operations
  }
}, 60000); // Check every minute
      `,
    },
    {
      practice: "Use efficient data formats",
      code: `
// Use compressed formats to reduce transfer costs
const compressedData = gzip(JSON.stringify(largeDataset));
await s3.write("data.json.gz", compressedData, {
  bucket: "research-bucket",
  requestPayer: true,
  contentType: "application/gzip"
});
      `,
    },
  ];

  bestPractices.forEach((practice, index) => {
    console.log(`\n   ${index + 1}. ${practice.practice}:`);
    console.log(practice.code);
  });
}

// Main demonstration
async function main() {
  try {
    await demonstrateBasicOperations();
    await demonstrateMultipartUploads();
    await demonstrateCostTracking();
    await demonstrateRealWorldUseCases();
    await demonstrateErrorHandling();

    console.log("\nüéØ Summary of Bun v1.3.6 S3 Requester Pays Support:");
    console.log(
      "   ‚úÖ Simple requestPayer: true option enables Requester Pays buckets",
    );
    console.log(
      "   üîß Works with all S3 operations (reads, writes, stat, uploads)",
    );
    console.log(
      "   üí∞ Cost-effective access to public datasets and shared resources",
    );
    console.log("   üìä Built-in cost tracking and budget management");
    console.log("   üöÄ Production-ready with retry logic and error handling");
    console.log(
      "   üåê Real-world applications in research, education, and media",
    );

    console.log("\nüí® S3 Requester Pays buckets are now enterprise-ready!");
  } catch (error) {
    console.error("‚ùå Demonstration failed:", error);
  }
}

if (import.meta.main) {
  main();
}

export {
  demonstrateBasicOperations,
  demonstrateCostTracking,
  demonstrateMultipartUploads,
  main as demonstrateS3RequesterPaysPractical,
};
